---
title: "Kaggle: Houseprice -stacking"
author: 'Sanghoo Ahn'
date: '2024-09-27'
categories: [Machine Learning]
jupyter: python3
---
## Kaggle 링크
[House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)

## 전처리

```{python}
# 필요한 패키지 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

np.random.seed(20240911) 

## 필요한 데이터 불러오기
house_train=pd.read_csv("train.csv")
house_test=pd.read_csv("test.csv")
sub_df=pd.read_csv("sample_submission.csv")

## NaN 채우기
# 각 숫치형 변수는 평균 채우기
# 각 범주형 변수는 Unknown 채우기
house_train.isna().sum()
house_test.isna().sum()

## 숫자형 채우기
quantitative = house_train.select_dtypes(include = [int, float])
quantitative.isna().sum()
quant_selected = quantitative.columns[quantitative.isna().sum() > 0]

for col in quant_selected:
    house_train[col] = house_train[col].fillna(house_train[col].mean())
house_train[quant_selected].isna().sum()

## 범주형 채우기
qualitative = house_train.select_dtypes(include = [object])
qualitative.isna().sum()
qual_selected = qualitative.columns[qualitative.isna().sum() > 0]

for col in qual_selected:
    house_train[col] = house_train[col].fillna("unknown")


# test 데이터 채우기
## 숫자형 채우기
quantitative = house_test.select_dtypes(include = [int, float])
quantitative.isna().sum()
quant_selected = quantitative.columns[quantitative.isna().sum() > 0]

for col in quant_selected:
    house_test[col] = house_test[col].fillna(house_train[col].mean())
house_test[quant_selected].isna().sum()

## 범주형 채우기
qualitative = house_test.select_dtypes(include = [object])
qualitative.isna().sum()
qual_selected = qualitative.columns[qualitative.isna().sum() > 0]

for col in qual_selected:
    house_test[col] = house_test[col].fillna("unknown")
house_test[qual_selected].isna().sum()


house_train.shape
house_test.shape
train_n=len(house_train)

# 통합 df 만들기 + 더미코딩
# house_test.select_dtypes(include=[int, float])

df = pd.concat([house_train, house_test], ignore_index=True)
# df.info()
df = pd.get_dummies(
    df,
    columns= df.select_dtypes(include=[object]).columns,
    drop_first=True
    )
df

# train / test 데이터셋
train_df=df.iloc[:train_n,]
test_df=df.iloc[train_n:,]

## 이상치 탐색
train_df=train_df.query("GrLivArea <= 4500")

## train
train_x=train_df.drop("SalePrice", axis=1)
train_y=train_df["SalePrice"]

## test
test_x=test_df.drop("SalePrice", axis=1)

# 표준화
from sklearn.preprocessing import StandardScaler
num_features = house_test.select_dtypes(include = [int, float]).columns

scaler = StandardScaler()
train_x[num_features] = scaler.fit_transform(train_x[num_features])
test_x[num_features] = scaler.transform(test_x[num_features])
```
  
## 모델 생성 및 예측
```{python}
# 부스트 모델 생성
import xgboost as xgb
from sklearn.model_selection import GridSearchCV

xgb_model = xgb.XGBRegressor(random_state=20240911)

param_grid = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1, 0.2],
    'max_depth': [3, 4, 5]
}

grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring='neg_mean_squared_error',
    cv=5
)

grid_search.fit(train_x, train_y)

best_params = grid_search.best_params_
best_xgb_model = grid_search.best_estimator_

# rf 모델 생성
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(random_state=20240911, n_estimators=100, max_features=None)

param_grid={
    'max_depth': [25],
    'min_samples_split': [3]
}

grid_search=GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    scoring='neg_mean_squared_error',
    cv=5
)

grid_search.fit(train_x,train_y)
grid_search.best_params_
best_rf_model=grid_search.best_estimator_

# 스택킹
y1_hat=best_xgb_model.predict(train_x)
y2_hat=best_rf_model.predict(train_x)

train_x_stack=pd.DataFrame({
    'y1':y1_hat,
    'y2':y2_hat
})

pred_y_xgb=best_xgb_model.predict(test_x)
pred_y_rf=best_rf_model.predict(test_x)

test_x_stack=pd.DataFrame({
    'y1': pred_y_xgb,
    'y2': pred_y_rf
})

# 블렌더
from sklearn.linear_model import LinearRegression
blender_model = LinearRegression()
blender_model.fit(train_x_stack, train_y)
pred_y = blender_model.predict(test_x_stack)

# SalePrice 바꿔치기
sub_df["SalePrice"] = pred_y
sub_df

# # csv 파일로 내보내기
sub_df.to_csv("sample_submission_boost_rf.csv", index=False)
```  

## 모델 성능
```{python}
# 모델 성능 평가
from sklearn.metrics import mean_squared_error
train_y_pred = blender_model.predict(train_x_stack)
mse = mean_squared_error(train_y, train_y_pred)
print(f"Mean Squared Error on training set: {mse:.2f}")
```  

  



<div id="disqus_thread"></div>
<script>
var disqus_config = function () {
    this.page.url = window.location.href;  // 현재 페이지 URL
    this.page.identifier = window.location.pathname; // 페이지 고유 식별자
};

(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://sanghoohoo.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>