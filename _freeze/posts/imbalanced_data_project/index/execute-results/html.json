{
  "hash": "7c2c8f5d6568cf74f6943949a8a5f50b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"제조업 불균형 데이터 프로젝트\"\nauthor: 'Sanghoo Ahn'\ndate: '2024-10-02'\ncategories: [Project]\njupyter: python3\n---\n\n\n## 최종 분석 코드\n\n::: {#b8f3a199 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import f1_score, classification_report\nimport lightgbm as lgb\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\n\n# 데이터 로드\ndf = pd.read_csv(\"week1.csv\")\n\n# feature engineering\ndf = df.drop(columns=['X4', 'X13', 'X18', 'X19', 'X20'])\n\nX = df.drop(\"Y\", axis=1)\ny = df['Y']\n\n# train/test 셋 분리\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # 칼럼별 왜도 계산--------------------------------------------------\n# skewness_values = X_train.apply(lambda x: x.skew())\n\n# # 결과를 데이터프레임으로 변환\n# skewness_table = pd.DataFrame({\n#     'Feature': skewness_values.index,\n#     'Skewness': skewness_values.values\n# })\n\n# # 왜도 테이블 출력\n# print(skewness_table)\n\n# # 로그/제곱 변환을 적용할 변수 선택\n# log_transform_features = skewness_table[skewness_table['Skewness'] > 2]['Feature'].tolist()\n# square_transform_features = skewness_table[skewness_table['Skewness'] < -2]['Feature'].tolist()\n\n# # 변환 적용\n# for feature in log_transform_features:\n#     X_train[feature] = np.log1p(X_train[feature])  # log(1 + x)\n#     X_test[feature] = np.log1p(X_test[feature])    # test set에도 동일한 변환 적용\n\n# for feature in square_transform_features:\n#     X_train[feature] = np.square(X_train[feature])\n#     X_test[feature] = np.square(X_test[feature])\n\n# StandardScaler 적용\n# scaler = StandardScaler()\n# X_train_scaled = scaler.fit_transform(X_train)\n# X_test_scaled = scaler.transform(X_test)\n\n# 스케일된 데이터를 DataFrame으로 변환\n# X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n# X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n#-----------------------------------------------------------------------\n\n# Polynomial Features 적용 \npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)\n\n# 스케일된 데이터를 DataFrame으로 변환\nX_train_poly = pd.DataFrame(X_train_poly, columns=poly.get_feature_names_out(X.columns))\nX_test_poly = pd.DataFrame(X_test_poly, columns=poly.get_feature_names_out(X.columns))\n\n# SMOTE 적용\nsmote = SMOTE(sampling_strategy=0.3, random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_poly, y_train)\n\n# SMOTE 적용 후 클래스 분포 확인\nprint(f\"Resampled dataset shape: {Counter(y_train_resampled)}\")\n\n# LightGBM 모델 초기화\nmodel = lgb.LGBMClassifier(\n    learning_rate=0.1789067697356303, \n    max_depth=-1, \n    n_estimators=387, \n    num_leaves=130\n)\n\n# 모델 학습\nmodel.fit(\n    X_train_resampled, y_train_resampled\n)\n\n# 예측\ny_pred = model.predict(X_test_poly)\ny_pred_proba = model.predict_proba(X_test_poly)\n\n# 평가지표 계산 함수 작성\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom imblearn.metrics import geometric_mean_score\nfrom sklearn.metrics import roc_curve, auc\n\ndef Eval(y_true, y_pred, y_pred_proba=None):\n    # F1 score 계산\n    f1 = f1_score(np.round(y_true), np.round(y_pred), average='weighted')\n    \n    # Geometric Mean (G-Mean) 계산\n    gmean = geometric_mean_score(np.round(y_true), np.round(y_pred), average='weighted')\n    \n    \n    # AUC 계산 \n    auc_score = roc_auc_score(y_true, y_pred_proba[:, 1]) if y_pred_proba is not None else None\n      \n    return {\n        \"F1 Score\": f1,\n        \"G-Mean\": gmean,\n        \"AUC\": auc_score\n    }\n\n # 성능 평가\nresults = Eval(y_test, y_pred, y_pred_proba)\n\n# 결과 출력\nfor metric, value in results.items():\n    print(f\"{metric}: {value}\")\n\n# 혼동행렬 시각화\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n# 혼동 행렬 계산\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# 혼동 행렬 시각화\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greys', cbar=False,\n            xticklabels=['Predicted Negative', 'Predicted Positive'],\n            yticklabels=['Actual Negative', 'Actual Positive'])\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n```\n:::\n\n\n## 프레젠테이션\n# PDF 파일 보기\n<iframe src=\"3!4!조최종보고서.pdf\" width=\"100%\" height=\"800px\">\n\n\n\n\n\n<div id=\"disqus_thread\"></div>\n<script>\nvar disqus_config = function () {\n    this.page.url = window.location.href;  // 현재 페이지 URL\n    this.page.identifier = window.location.pathname; // 페이지 고유 식별자\n};\n\n(function() { // DON'T EDIT BELOW THIS LINE\n    var d = document, s = d.createElement('script');\n    s.src = 'https://sanghoohoo.disqus.com/embed.js';\n    s.setAttribute('data-timestamp', +new Date());\n    (d.head || d.body).appendChild(s);\n})();\n</script>\n<noscript>Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\">comments powered by Disqus.</a></noscript>\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}